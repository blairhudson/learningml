{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](00.00-Learning-ML.ipynb#Table-of-Contents) &bull; [&larr; *Chapter 2.02 - Naive Bayes*](02.02-Naive-Bayes.ipynb) &bull; [*Chapter 2.04 - ?* &rarr;](02.04-?.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "# Chapter 2.03 - k-Nearest Neighbours\n",
    "\n",
    "k-Nearest Neighbours, or KNN, is an algorithm that uses the *distance* between the feature values to find a specified number of the \"closest\" observations (as measured by having a small distance). Predictions are assigned by selecting the majority class from the set of closest observations.\n",
    "\n",
    "The number of closest observations to consider can be changed for each model. This number is denoted (known as) \"k\" - hence the algorithm's name k-Nearest Neighbours.\n",
    "\n",
    "KNN models, unlike Naive Bayes, actually do very little work during training. The model essentially stores an unprocessed copy of the input observations (X) and their corresponding outputs (y). To make predictions,  the new input X is compared (by distance) to all of the stored observations. This is done for every prediction, and hence producing predictions takes for more computation time per prediction, especially as the number of observations increases.\n",
    "\n",
    "The benefit of KNN is that relationships between each of the features are implicitly considered, so we can potentially achieve a better performing model.\n",
    "\n",
    "## Measuring distance\n",
    "\n",
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[[1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "[[0 1]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509203681473\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[Table of Contents](00.00-Learning-ML.ipynb#Table-of-Contents) &bull; [&larr; *Chapter 2.02 - Naive Bayes*](02.02-Naive-Bayes.ipynb) &bull; [*Chapter 2.04 - ?* &rarr;](02.04-?.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
